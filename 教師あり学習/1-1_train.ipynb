{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries 📚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import easydict\n",
    "from glob import glob\n",
    "from natsort import natsorted\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import tensorboardX as tbx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random seed🌱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#再現性の確保\n",
    "seed = 44\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    #Disabling the benchmark by CUDA convolution operation(GPUを使うときの再現性の担保) (https://pytorch.org/docs/stable/notes/randomness.html)\n",
    "    torch.backends.cudnn.benchmark = False \n",
    "    torch.backends.cudnn.determinstic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments 📗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"batch_size\" : 32, # バッチサイズ\n",
    "    \"learning_rate\" : 0.0001, # 損失が下がりきらない場合は下げるといいかも？　adamのデフォルト0.001\n",
    "    \"epochs\":1000, # 学習回数\n",
    "    \"early_stop_patience\" : 15, # 損失が下がらなかったら学習を打ち切る回数\n",
    "\n",
    "    \"train_size\" : 40000,\n",
    "    \"valid_size\" : 10000,\n",
    "\n",
    "    \"model_save_path\" : \"check_point\", # モデル保存ディレクトリ\n",
    "    \"model_file_name\" : \"model_data40000\", # モデル名\n",
    "\n",
    "    \"gamma\" : 1, # 特に意味なし\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU 📺"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_GPU():\n",
    "    \"\"\"\n",
    "    使用するデバイスを出力する関数\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    device : object\n",
    "        GPUが使えるなら'cuda:0',使えないなら'cpu'を返す\n",
    "    \"\"\"\n",
    "    print(\"Check GPU\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"You can use GPU({torch.cuda.get_device_name()})\")\n",
    "        d_type = \"cuda:0\"\n",
    "    else:\n",
    "        print(\"You use cpu\")\n",
    "        d_type = \"cpu\"\n",
    "    print(\"-----\")\n",
    "    device = torch.device(d_type)\n",
    "    return device "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Procceing 🎛"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_normalization(train_df, num=500):\n",
    "    \"\"\"\n",
    "    画像の標準化を行うためにデータの平均と標準偏差を求める関数\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_path_list : list\n",
    "        globで集めた画像path\n",
    "    num : int\n",
    "        平均と標準偏差を求めるのに使う画像枚数 \n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mean : tuple\n",
    "        データセットの画素の平均\n",
    "    std : tuple\n",
    "        データセットの画素の標準偏差    \n",
    "    \"\"\"\n",
    "\n",
    "    tensors = []\n",
    "    to_tensor = transforms.ToTensor()\n",
    "    sample_df = train_df.sample(num)\n",
    "    img_path_list = sample_df[\"fname\"]\n",
    "    for img in img_path_list:\n",
    "        img = Image.open(img)\n",
    "        img = to_tensor(img)\n",
    "        tensors.append(img)\n",
    "    tensors = torch.stack([img_t for img_t in tensors], dim=3) #dimはどこでもよい\n",
    "    mean = tensors.view(1,-1).mean(dim=1).item()\n",
    "    std = tensors.view(1,-1).std(dim=1).item()\n",
    "    \n",
    "    df = pd.DataFrame({\"mean\":[mean],\n",
    "                       \"std\":[std]})\n",
    "    df.to_csv(\"mean_std.csv\")\n",
    "    \n",
    "    return mean, std    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set 🧰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform:\n",
    "    \"\"\"\n",
    "    pytorchでの画像の前処理クラス\n",
    "    訓練時だけ、データオーギュメンテーション(DA)ができるように、train,validで分けて書いた\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    mean : int\n",
    "        データセットの画素値の平均値\n",
    "    std : int\n",
    "        データセットの画素値の標準偏差\n",
    "    \"\"\"   \n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        self.data_transform = {\n",
    "            'train':transforms.Compose([\n",
    "                #transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std) \n",
    "            ]),\n",
    "            'valid':transforms.Compose([\n",
    "                #transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ])\n",
    "        }\n",
    "    \n",
    "    #引数なしで呼ばれたときの挙動を定義\n",
    "    def __call__(self, img, phase='train'):\n",
    "        return self.data_transform[phase](img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_Dataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    画像のデータセットクラス。\n",
    "    Pytorch Dataset class を継承\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        学習データ       \n",
    "    transform : object\n",
    "        class ImageTransform()    \n",
    "    phase : str\n",
    "        'train' or 'valid'\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, transform, phase='train'):\n",
    "        self.file_list = df[\"fname\"] \n",
    "        self.labels = df[[\"dx\",\"dy\"]].to_numpy()\n",
    "        self.l = df[\"l\"]\n",
    "        self.transform = transform  \n",
    "        self.phase = phase  \n",
    "\n",
    "    #このクラスの画像枚数を定義。\n",
    "    def __len__(self):\n",
    "        return len(self.file_list) \n",
    "\n",
    "    #このクラスに角括弧でアクセスした時の挙動を定義\n",
    "    def __getitem__(self, index):\n",
    "        # 画像をロード\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path)\n",
    "        #img = img.convert(\"L\") #グレイスケール \n",
    "        # 前処理\n",
    "        img_transformed = self.transform(\n",
    "            img, self.phase)  # torch.Size([width, height]) \n",
    "\n",
    "        #label\n",
    "        label = self.labels[index]\n",
    "        #Tensorに変換\n",
    "        label = torch.tensor(label, dtype=torch.float32) \n",
    "\n",
    "        # ワーキングディスタンス\n",
    "        l = self.l[index]           \n",
    "\n",
    "        return img_transformed, label, #l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetWork 🧠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 残差ブロック\n",
    "\n",
    "\n",
    "class block(nn.Module):\n",
    "    def __init__(self, first_conv_in_channels, first_conv_out_channels, identity_conv=None, stride=1):\n",
    "        \"\"\"\n",
    "        残差ブロックを作成するクラス\n",
    "        Args:\n",
    "            first_conv_in_channels : 1番目のconv層（1×1）のinput channel数\n",
    "            first_conv_out_channels : 1番目のconv層（1×1）のoutput channel数\n",
    "            identity_conv : channel数調整用のconv層\n",
    "            stride : 3×3conv層におけるstide数。sizeを半分にしたいときは2に設定\n",
    "        \"\"\"        \n",
    "        super(block, self).__init__()\n",
    "\n",
    "        # 1番目のconv層（1×1）\n",
    "        self.conv1 = nn.Conv2d(first_conv_in_channels, first_conv_out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(first_conv_out_channels)\n",
    "\n",
    "        # 2番目のconv層（3×3）\n",
    "        # パターン3の時はsizeを変更できるようにstrideは可変\n",
    "        self.conv2 = nn.Conv2d(first_conv_out_channels, first_conv_out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(first_conv_out_channels)\n",
    "\n",
    "        # 3番目のconv層（1×1）\n",
    "        # output channelはinput channelの4倍になる\n",
    "        self.conv3 = nn.Conv2d(first_conv_out_channels, first_conv_out_channels*4, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(first_conv_out_channels*4)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # identityのchannel数の調整が必要な場合はconv層（1×1）を用意、不要な場合はNone\n",
    "        self.identity_conv = identity_conv\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        identity = x.clone()  # 入力を保持する\n",
    "\n",
    "        x = self.conv1(x)  # 1×1の畳み込み\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)  # 3×3の畳み込み（パターン3の時はstrideが2になるため、ここでsizeが半分になる）\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv3(x)  # 1×1の畳み込み\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        # 必要な場合はconv層（1×1）を通してidentityのchannel数の調整してから足す\n",
    "        if self.identity_conv is not None:\n",
    "            identity = self.identity_conv(identity)\n",
    "        x += identity\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Resnet50\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self,block):\n",
    "        super(ResNet,self).__init__()\n",
    "\n",
    "        # conv1はアーキテクチャ通りにベタ打ち\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # conv2_xはサイズの変更は不要のため、strideは1\n",
    "        self.conv2_x = self._make_layer(block, 3, res_block_in_channels=64, first_conv_out_channels=64, stride=1)\n",
    "\n",
    "        # conv3_x以降はサイズの変更をする必要があるため、strideは2\n",
    "        self.conv3_x = self._make_layer(block, 4, res_block_in_channels=256,  first_conv_out_channels=128, stride=2)\n",
    "        self.conv4_x = self._make_layer(block, 6, res_block_in_channels=512,  first_conv_out_channels=256, stride=2)\n",
    "        self.conv5_x = self._make_layer(block, 3, res_block_in_channels=1024, first_conv_out_channels=512, stride=2)\n",
    "\n",
    "        #self.avgpool = nn.AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc1 = nn.Identity()\n",
    "        #self.fc2 = nn.Linear(224,2)\n",
    "\n",
    "        # Regression\n",
    "        self.regression = nn.Sequential(\n",
    "            nn.Linear(2048, 512), \n",
    "            nn.LeakyReLU(),       \n",
    "            nn.Linear(512, 128),  \n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 32),        \n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.conv1(x)   # in:(3,224*224)、out:(64,112*112)\n",
    "        x = self.bn1(x)     # in:(64,112*112)、out:(64,112*112)\n",
    "        x = self.relu(x)    # in:(64,112*112)、out:(64,112*112)\n",
    "        x = self.maxpool(x) # in:(64,112*112)、out:(64,56*56)\n",
    "\n",
    "        x = self.conv2_x(x)  # in:(64,56*56)  、out:(256,56*56)\n",
    "        x = self.conv3_x(x)  # in:(256,56*56) 、out:(512,28*28)\n",
    "        x = self.conv4_x(x)  # in:(512,28*28) 、out:(1024,14*14)\n",
    "        x = self.conv5_x(x)  # in:(1024,14*14)、out:(2048,7*7)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        #x = self.fc2(x)\n",
    "\n",
    "        x = self.regression(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, block, num_res_blocks, res_block_in_channels, first_conv_out_channels, stride):\n",
    "        layers = []\n",
    "\n",
    "        # 1つ目の残差ブロックではchannel調整、及びsize調整が発生する\n",
    "        # identifyを足す前に1×1のconv層を追加し、サイズ調整が必要な場合はstrideを2に設定\n",
    "        identity_conv = nn.Conv2d(res_block_in_channels, first_conv_out_channels*4, kernel_size=1,stride=stride)\n",
    "        layers.append(block(res_block_in_channels, first_conv_out_channels, identity_conv, stride))\n",
    "\n",
    "        # 2つ目以降のinput_channel数は1つ目のoutput_channelの4倍\n",
    "        in_channels = first_conv_out_channels*4\n",
    "\n",
    "        # channel調整、size調整は発生しないため、identity_convはNone、strideは1\n",
    "        for i in range(num_res_blocks - 1):\n",
    "            layers.append(block(in_channels, first_conv_out_channels, identity_conv=None, stride=1))\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function 🛗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressison_loss_function(output, labels, args=args):\n",
    "    \"\"\"\n",
    "    平均二乗誤差．コントラスト学習と同じ形にしてるだけ\n",
    "    Attributes\n",
    "    ----------\n",
    "    output : torch.tensor\n",
    "        モデルからの出力\n",
    "    labels : torch.tensor\n",
    "        空気揺らぎラベル\n",
    "    Returns\n",
    "    ----------\n",
    "    loss : torch.tensor\n",
    "        平均二乗誤差(Loss_mse)\n",
    "    \"\"\"\n",
    "    criterion = nn.MSELoss()\n",
    "    loss = args.gamma * criterion(output, labels) / args.batch_size\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train 🏋️‍♂️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloaders_dict, device, opt, writer, earlystopping):\n",
    "\n",
    "    BREAK = False\n",
    "    print(f\"\\nStarting training\")\n",
    "    for epoch in range(0, args.epochs+1):\n",
    "\n",
    "        # epochごとの学習と検証のループ\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # モデルを訓練モードに\n",
    "            else:\n",
    "                model.eval()   # モデルを検証モードに\n",
    "\n",
    "            epoch_loss = 0.0  # epochの損失和                \n",
    "\n",
    "            #未訓練時の性能評価\n",
    "            if (epoch == 0 and phase=='train'):\n",
    "                continue\n",
    "            \n",
    "            # データローダーからミニバッチを取り出すループ。args['batch_size']枚ごと取り出す\n",
    "            for inputs, labels in tqdm(dataloaders_dict[phase], leave=False, desc='Epoch {}/{} {}'.format(epoch, args.epochs, phase)): \n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # optimizerを初期化\n",
    "                opt.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = regressison_loss_function(outputs, labels)  # 損失を計算。\n",
    "\n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward() \n",
    "                        opt.step()\n",
    "\n",
    "                # 損失の計算\n",
    "                if phase == 'train':\n",
    "                    epoch_loss += loss.item()*args.batch_size\n",
    "                elif phase == 'valid':\n",
    "                    epoch_loss += loss.item()*args.batch_size\n",
    "\n",
    "            #tensorboardに出力\n",
    "            if phase == 'train':\n",
    "                writer.add_scalar('train_epoch_loss', epoch_loss, epoch) #(グラフ名, y座標, x座標)                \n",
    "            elif phase == 'valid':\n",
    "                writer.add_scalar(f'valid_epoch_loss', epoch_loss, epoch)                  \n",
    "                #毎エポックearlystoppingの判定をさせる\n",
    "                earlystopping(epoch_loss, model) #callメソッド呼び出し\n",
    "                if earlystopping.early_stop: #ストップフラグがTrueの場合、breakでforループを抜ける\n",
    "                    print(\"Early Stopping!\")\n",
    "                    BREAK = True\n",
    "        if BREAK:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EarlyStopping ⛔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    earlystoppingクラス\n",
    "    損失が下がったことを判断して学習を打ち切る\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    patience : int\n",
    "        何回損失が下がらなかったら学習を打ち切るか\n",
    "    verbose : bool\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience, verbose):\n",
    "        \"\"\"引数 : 最小値の非更新数カウンタ、表示設定\"\"\"\n",
    "\n",
    "        self.patience = patience    #設定ストップカウンタ\n",
    "        self.verbose = verbose      #表示の有無\n",
    "        self.counter = 0            #現在のカウンタ値\n",
    "        self.best_score = None      #ベストスコア\n",
    "        self.early_stop = False     #ストップフラグ\n",
    "        self.val_loss_min = np.Inf   #前回のベストスコア記憶用\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        \"\"\"\n",
    "        特殊(call)メソッド\n",
    "        実際に学習ループ内で最小lossを更新したか否かを計算させる部分\n",
    "        \"\"\"\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:  #1Epoch目の処理\n",
    "            self.best_score = score   #1Epoch目はそのままベストスコアとして記録する\n",
    "            self.checkpoint(val_loss, model)  #記録後にモデルを保存してスコア表示する\n",
    "        elif score < self.best_score:  # ベストスコアを更新できなかった場合\n",
    "            self.counter += 1   #ストップカウンタを+1\n",
    "            # if self.verbose:  #表示を有効にした場合は経過を表示\n",
    "            #     print(f'EarlyStopping counter: {self.counter} out of {self.patience}')  #現在のカウンタを表示する \n",
    "            if self.counter >= self.patience:  #設定カウントを上回ったらストップフラグをTrueに変更\n",
    "                self.early_stop = True\n",
    "        else:  #ベストスコアを更新した場合\n",
    "            self.best_score = score  #ベストスコアを上書き\n",
    "            self.checkpoint(val_loss, model)  #モデルを保存してスコア表示\n",
    "            self.counter = 0  #ストップカウンタリセット\n",
    "\n",
    "    def checkpoint(self, val_loss, model):\n",
    "        '''ベストスコア更新時に実行されるチェックポイント関数'''\n",
    "        if self.verbose:  #表示を有効にした場合は、前回のベストスコアからどれだけ更新したか？を表示\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        save_path = os.path.join(args.model_save_path, f'{args.model_file_name}.pth')\n",
    "        torch.save(model.state_dict(), save_path)  #ベストモデルを指定したpathに保存\n",
    "        self.val_loss_min = val_loss  #その時のlossを記録する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Main 🏃‍♀️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check GPU\n",
      "You can use GPU(NVIDIA GeForce RTX 3080)\n",
      "-----\n",
      "\n",
      "Starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 2790.492230).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2790.492230 --> 2026.234539).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2026.234539 --> 1526.072839).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1526.072839 --> 769.001788).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (769.001788 --> 597.033066).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (597.033066 --> 448.278090).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (448.278090 --> 319.169289).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (319.169289 --> 302.218566).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (302.218566 --> 278.370721).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (278.370721 --> 275.519922).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (275.519922 --> 229.754846).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (229.754846 --> 204.603066).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (204.603066 --> 188.723561).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (188.723561 --> 172.844775).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (172.844775 --> 172.065712).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# 時間計測開始\n",
    "time_start = time.time()\n",
    "\n",
    "#GPU\n",
    "device = check_GPU()\n",
    "\n",
    "os.makedirs(args.model_save_path, exist_ok=True) #重みファイルの保存ディレクトリ\n",
    "# 学習条件の保存\n",
    "csv_file = os.path.join(args.model_save_path,f\"{args.model_file_name}_info.csv\")\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    saver = csv.writer(file)\n",
    "    # ヘッダー（辞書のキー）を書き込む\n",
    "    saver.writerow(args.keys())\n",
    "    # データ（辞書の値）を書き込む\n",
    "    saver.writerow(args.values())\n",
    "\n",
    "train_df = pd.read_csv(\"train.csv\")[:args.train_size]\n",
    "valid_df = pd.read_csv(\"valid.csv\")[:args.valid_size]\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "dataset_dict = {\n",
    "        \"train\":train_df,\n",
    "        \"valid\":valid_df,\n",
    "        \"test\":test_df\n",
    "    }\n",
    "\n",
    "#画像の標準化\n",
    "mean, std = image_normalization(dataset_dict[\"train\"])\n",
    "\n",
    "transform = ImageTransform(mean, std)\n",
    "\n",
    "#logger\n",
    "writer = tbx.SummaryWriter()\n",
    "\n",
    "# Dataset\n",
    "train_dataset = Image_Dataset(df=dataset_dict[\"train\"], transform=transform, phase='train') \n",
    "valid_dataset = Image_Dataset(df=dataset_dict[\"valid\"], transform=transform, phase='valid')\n",
    "\n",
    "# make dataloader\n",
    "train_dataloader=torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    "    )\n",
    "\n",
    "valid_dataloader=torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    "    )\n",
    "\n",
    "# 辞書型変数にまとめる\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"valid\": valid_dataloader}          \n",
    "\n",
    "#Network\n",
    "model = ResNet(block)\n",
    "model.to(device)\n",
    "\n",
    "#optimizer\n",
    "opt = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "#early topping \n",
    "earlystopping = EarlyStopping(patience=args.early_stop_patience, verbose=True) \n",
    "\n",
    "#train\n",
    "train(model, dataloaders_dict, device, opt, writer, earlystopping)\n",
    "\n",
    "writer.close()\n",
    "\n",
    "#時間計測終了\n",
    "time_end = time.time()\n",
    "#経過時間（秒）\n",
    "elapsed = time_end - time_start\n",
    "#秒➡時間\n",
    "td = datetime.timedelta(seconds=elapsed)\n",
    "#経過時間記憶\n",
    "f = open('elapsed_time.txt','a')\n",
    "f.write(f\"{args.model_file_name}.pth : {str(td)} ,\")\n",
    "f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　{ヽﾐ∧\n",
    "    　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　 　 彡彡 　 .＼\n",
    "    　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　 　 彡彡　　　 .● ヽ\n",
    "    　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　 彡　　 （　　　　＼\n",
    "    　　　　　　　　　　　　　　　　 ＿───────────＿＿＿＿──../　             /ヽ 　   ヽ　　 ／￣￣￣￣￣￣￣￣\n",
    "    　　　　　　　　　　　　　　　／　　　 　 　 /　 　 　 ./　　　　　　 　 ./　　ヽ　o丿　＜　ワープに使ってください\n",
    "    　 　 　 　 　 　 　 彡彡彡　 　 　 　 　 ./　　　　　/　　　　　 　 　  │ 　 　 　 　 　 ＼＿＿＿＿＿＿＿＿\n",
    "    　　 　 　 　 　 彡彡彡彡　　　 　 　 　  |ｺﾞｰﾙﾄﾞｼｯﾌﾟ/　　　　　　 　 　 │\n",
    "    　　 　 　 彡彡彡　　　 /　　　　　　　 ..￣￣￣￣￣　 .ヽ、　 　 　 ヽ　ﾉ\n",
    "    　　 　 彡彡　　　　 　 ﾉ　 　 　 ／￣￣｀ ヽ ､　　 　 　 　 ｀､　　 　 ﾉ　＼\n",
    "    　　　 彡　　　　　　 ／　　 ／　｀､　　　／　　 ｀　ー ､ ＿＿ヽ　　 ヽ　 　  ヽ 、\n",
    "    　　　　　 　 　 　 ／ 　 ／　　　 /　　 /　　　　　　　　 　 　 　 ＼　 丶　- ､ ｀､\n",
    "    　　　　　　　　　/　.／　　　　／ 　 ／　　　　　　　　　　　　　　　 ＼　｀､　　＼＼\n",
    "    　　　　 　 　 .／.／　　　　　 |　　/　　　　　　　　　　　　　　　 　  ＼ 丶 　 　ヽ ヽ\n",
    "    　　　 　 ___／.／　 　 　 　 　 |　|　　　　　　　　　　　　　　　　　　　ヽ｀､ 　 　｀､｀､\n",
    "    　　　　/ |__／　　　　　　　　　 | |　　　　　　　　　　　　　　　　　　　　｀､ヽ、　　 ｔﾆゝ\n",
    "    　　 　 ￣　　 　 　 　 　 　 \"\"\"\"''\"\"'\"\" 　　　　　　　　　　　　　 　 　 　 ヽ ､ヽ　　　\n",
    "    　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　 　 　 　 　 　 ｔﾆゝ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47ea100d4d22683a1a742dc2bd2efe2b65c3502de462e7274ffa362f8c9b6784"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
