{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries 📚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import easydict\n",
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.utils.data as data\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "from glob import glob\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "import tensorboardX as tbx\n",
    "import csv\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random seed🌱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#再現性の確保\n",
    "seed = 44\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    #Disabling the benchmark by CUDA convolution operation(GPUを使うときの再現性の担保) (https://pytorch.org/docs/stable/notes/randomness.html)\n",
    "    torch.backends.cudnn.benchmark = False \n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments 📗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"batch_size\":32, # 何枚同時にモデルを画像に入力するか\n",
    "    \"epochs\":100000, #アーリーストッピングの\n",
    "    \"learning_rate\" : 0.0001, # 損失が下がりきらない場合は下げるといいかも？　adamのデフォルト0.001\n",
    "    \"early_stop_patience\" : 25,\n",
    "\n",
    "    \"label_path\" : r\"E:\\2023_3_chuouseiki_WorkingDistance\\resize224\\L*mm\\GroundTruth_ZeroEdge_Cutoff10%.csv\", #正解ラベルcsvファイル\n",
    "    \n",
    "    \"model_save_path\" : \"Checkpoints\",\n",
    "    \"model_file_name\" : \"model_data40000\",\n",
    "    \n",
    "    \"train_size\" : 40000,\n",
    "    \"valid_size\" : 10000,\n",
    "    \n",
    "    #損失関数のパラメータ\n",
    "    \"tau\" : 0.5, # 温度τが小さいほど正・負のサンプル間の差が大きくなり、τが大きくなると、正の類似度は1に近づき、正・負のサンプル間の差は小さくなります。\n",
    "    \"tau2\" : 0.5, #小さいとコントラストが付きやすくなるが，無限に発散することに注意.\n",
    "    \"gamma\" : 1, #回帰損失を重視する割合,\n",
    "    \"note\": \"コントラスト:回帰=?:1\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU 📺"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_GPU():\n",
    "    \"\"\"\n",
    "    使用するデバイスを出力する関数\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    device : object\n",
    "        GPUが使えるなら'cuda:0',使えないなら'cpu'を返す\n",
    "    \"\"\"\n",
    "    print(\"Check GPU\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"You can use GPU({torch.cuda.get_device_name()})\")\n",
    "        d_type = \"cuda:0\"\n",
    "    else:\n",
    "        print(\"You use cpu\")\n",
    "        d_type = \"cpu\"\n",
    "    print(\"-----\")\n",
    "    device = torch.device(d_type)\n",
    "    return device "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image & Label 📂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_divisible(a:int, b:int):\n",
    "    \"\"\"\n",
    "    バッチサイズで割り切れるデータ数を求めるための関数\n",
    "    \"\"\"\n",
    "    remainder = a % b\n",
    "    if remainder == 0:\n",
    "        return int(a)  # aはすでにbで割り切れる\n",
    "    elif remainder >= b / 2:\n",
    "        return int(a + (b - remainder))  # aを増やしてbの次の倍数にする\n",
    "    else:\n",
    "        return int(a - remainder)  # aを減らしてbの現在の倍数にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_label_collector(args=args):\n",
    "\n",
    "    \"\"\"\n",
    "    画像とラベルを集める関数\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    dataset_dict:dict\n",
    "    \"\"\"\n",
    "\n",
    "    paths = natsorted(glob(args.label_path))\n",
    "    df = pd.DataFrame()\n",
    "    for path in tqdm(paths, desc=\"preparing data...\", leave=False):\n",
    "        df_ = pd.read_csv(path)\n",
    "        # データフレームにWD追加\n",
    "        l = int(re.findall(\"L(\\d+)mm\",path)[0])\n",
    "        df_[\"l\"] = l\n",
    "        # 揺らぎ量(水平＋垂直)\n",
    "        df_[\"d\"] = np.sqrt(df_[\"dx\"]**2 + df_[\"dy\"]**2) \n",
    "        # 揺らぎ量順にソート\n",
    "        df_.sort_values(by=\"d\", inplace=True)\n",
    "        # 結合\n",
    "        df = pd.concat([df,df_])\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # データ２分割\n",
    "    df1 = df[::2]\n",
    "    df2 = df[1::2]\n",
    "\n",
    "    # 全データ数\n",
    "    all_data_num = len(df1)\n",
    "    # WDごとにグループ分けしたときの1グループあたりのデータ数\n",
    "    each_group_num = int(all_data_num//(args.batch_size/2))\n",
    "    # 余り\n",
    "    reminder_num = int(all_data_num%(args.batch_size/2))\n",
    "    # 余り分を近距離データから削除\n",
    "    df1 = df1[reminder_num:].reset_index(drop=True)\n",
    "    df2 = df2[reminder_num:].reset_index(drop=True)\n",
    "    # WDごとにグループ分け\n",
    "    df1[\"l_group\"] = 0\n",
    "    df2[\"l_group\"] = 0\n",
    "    for i in range(int(args.batch_size/2)):\n",
    "        df1[\"l_group\"][each_group_num*i:each_group_num*(i+1)] = i\n",
    "        df2[\"l_group\"][each_group_num*i:each_group_num*(i+1)] = i\n",
    "\n",
    "    #　データ数をバッチサイズで割り切れる数にする\n",
    "    train_data_num = find_closest_divisible(args.train_size, int(args.batch_size/2))\n",
    "    valid_data_num = find_closest_divisible(args.valid_size, int(args.batch_size/2))\n",
    "\n",
    "    # 訓練データ抽選\n",
    "    train_df1 = df1.sample(train_data_num,random_state=seed)\n",
    "    train_df2 = df2.sample(train_data_num,random_state=seed)\n",
    "    # サンプルした行のインデックスを取得.df1とdf2はindexが一致してる\n",
    "    sampled_indexes = train_df1.index\n",
    "    # 元のDataFrameからサンプルした行を削除\n",
    "    df1 = df1.drop(sampled_indexes)\n",
    "    df2 = df2.drop(sampled_indexes)\n",
    "    # 検証データ抽出\n",
    "    valid_df1 = df1.sample(valid_data_num,random_state=seed)\n",
    "    valid_df2 = df2.sample(valid_data_num,random_state=seed)\n",
    "    # サンプルした行のインデックスを取得.df1とdf2はindexが一致してる\n",
    "    sampled_indexes = valid_df1.index\n",
    "    # 元のDataFrameからサンプルした行を削除\n",
    "    df1 = df1.drop(sampled_indexes)\n",
    "    df2 = df2.drop(sampled_indexes)\n",
    "    # データフレームをシャッフルし、シード値を固定\n",
    "    df1 = df1.sample(frac=1, random_state=seed)\n",
    "    df2 = df2.sample(frac=1, random_state=seed)\n",
    "\n",
    "    # 交互に(args.batch_size/2)行ずつデータを取り出し、結合する\n",
    "    train_df = pd.DataFrame()\n",
    "    for i in tqdm(range(0, len(train_df1), int(args.batch_size/2)), desc=\"sorting train data...\", leave=False):\n",
    "        train_df = pd.concat([train_df, train_df1[i:i+int(args.batch_size/2)], train_df2[i:i+int(args.batch_size/2)]])\n",
    "    valid_df = pd.DataFrame()\n",
    "    for i in tqdm(range(0, len(valid_df1), int(args.batch_size/2)), desc=\"sorting valid data...\", leave=False):\n",
    "        valid_df = pd.concat([valid_df, valid_df1[i:i+int(args.batch_size/2)], valid_df2[i:i+int(args.batch_size/2)]])\n",
    "    # テストデータはそのまま結合\n",
    "    test_df = pd.concat([df1,df2])\n",
    "\n",
    "    # 辞書型にまとめる．\n",
    "    dataset_dict = {\n",
    "        \"train\" : train_df,\n",
    "        \"valid\" : valid_df,\n",
    "        \"test\" : test_df,\n",
    "    }\n",
    "\n",
    "    # 保存\n",
    "    for key, value in dataset_dict.items():\n",
    "        value.to_csv(f\"{key}.csv\",index=False)\n",
    "    \n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization 📊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_normalization(train_df, num=500):\n",
    "    \"\"\"\n",
    "    画像の標準化を行うためにデータの平均と標準偏差を求める関数\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_path_list : list\n",
    "        globで集めた画像path\n",
    "    num : int\n",
    "        平均と標準偏差を求めるのに使う画像枚数 \n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mean : tuple\n",
    "        データセットの画素の平均\n",
    "    std : tuple\n",
    "        データセットの画素の標準偏差    \n",
    "    \"\"\"\n",
    "\n",
    "    tensors = []\n",
    "    to_tensor = transforms.ToTensor()\n",
    "    sample_df = train_df.sample(num)\n",
    "    img_path_list = sample_df[\"fname\"]\n",
    "    for img in img_path_list:\n",
    "        img = Image.open(img)\n",
    "        img = to_tensor(img)\n",
    "        tensors.append(img)\n",
    "    tensors = torch.stack([img_t for img_t in tensors], dim=3) #dimはどこでもよい\n",
    "    mean = tensors.view(1,-1).mean(dim=1).item()\n",
    "    std = tensors.view(1,-1).std(dim=1).item()\n",
    "    \n",
    "    df = pd.DataFrame({\"mean\":[mean],\n",
    "                       \"std\":[std]})\n",
    "    df.to_csv(\"mean_std.csv\")\n",
    "    \n",
    "    return mean, std    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data set 🧰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform:\n",
    "    \"\"\"\n",
    "    画像の前処理クラス\n",
    "    訓練時だけ、データオーギュメンテーション(DA)ができるように、train,validで分けて書いた\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    mean : int\n",
    "        データセットの画素値の平均値\n",
    "    std : int\n",
    "        データセットの画素値の標準偏差\n",
    "    \"\"\"   \n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        self.data_transform = {\n",
    "            'train':transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std) \n",
    "            ]),\n",
    "            'valid':transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ])\n",
    "        }\n",
    "    \n",
    "    #引数なしで呼ばれたときの挙動を定義\n",
    "    def __call__(self, img, phase='train'):\n",
    "        return self.data_transform[phase](img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_Dataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    画像のデータセットクラス。\n",
    "    Pytorch Dataset class を継承\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    file_list : list\n",
    "        画像のpath_list\n",
    "    label_list : list\n",
    "        ラベルのpath_list       \n",
    "    transform : object\n",
    "        class ImageTransform()    \n",
    "    phase : str\n",
    "        'train' or 'valid'\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, transform, phase='train'):\n",
    "        self.file_list = df[\"fname\"] \n",
    "        self.labels = df[[\"dx\",\"dy\"]].to_numpy()\n",
    "        #self.l = df[\"l\"]\n",
    "        self.d = df[\"d\"]\n",
    "        self.transform = transform  \n",
    "        self.phase = phase  \n",
    "\n",
    "    #このクラスの画像枚数を定義。\n",
    "    def __len__(self):\n",
    "        return len(self.file_list) \n",
    "\n",
    "    #このクラスに角括弧でアクセスした時の挙動を定義\n",
    "    def __getitem__(self, index):\n",
    "        # 画像をロード\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path)\n",
    "        #img = img.convert(\"L\") #グレイスケール \n",
    "        # 前処理\n",
    "        img_transformed = self.transform(\n",
    "            img, self.phase)  # torch.Size([width, height]) \n",
    "\n",
    "        #label\n",
    "        label = self.labels[index]\n",
    "        #Tensorに変換\n",
    "        label = torch.tensor(label, dtype=torch.float32) \n",
    "\n",
    "        # 空気揺らぎ量\n",
    "        d = self.d[index]           \n",
    "\n",
    "        return img_transformed, label, d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetWork 🧠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデル\n",
    "\n",
    "# # 残差ブロック\n",
    "class block(nn.Module):\n",
    "    def __init__(self, first_conv_in_channels, first_conv_out_channels, identity_conv=None, stride=1):\n",
    "        \"\"\"\n",
    "        残差ブロックを作成するクラス\n",
    "        Args:\n",
    "            first_conv_in_channels : 1番目のconv層（1×1）のinput channel数\n",
    "            first_conv_out_channels : 1番目のconv層（1×1）のoutput channel数\n",
    "            identity_conv : channel数調整用のconv層\n",
    "            stride : 3×3conv層におけるstide数。sizeを半分にしたいときは2に設定\n",
    "        \"\"\"        \n",
    "        super(block, self).__init__()\n",
    "\n",
    "        # 1番目のconv層（1×1）\n",
    "        self.conv1 = nn.Conv2d(first_conv_in_channels, first_conv_out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(first_conv_out_channels)\n",
    "\n",
    "        # 2番目のconv層（3×3）\n",
    "        # パターン3の時はsizeを変更できるようにstrideは可変\n",
    "        self.conv2 = nn.Conv2d(first_conv_out_channels, first_conv_out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(first_conv_out_channels)\n",
    "\n",
    "        # 3番目のconv層（1×1）\n",
    "        # output channelはinput channelの4倍になる\n",
    "        self.conv3 = nn.Conv2d(first_conv_out_channels, first_conv_out_channels*4, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(first_conv_out_channels*4)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # identityのchannel数の調整が必要な場合はconv層（1×1）を用意、不要な場合はNone\n",
    "        self.identity_conv = identity_conv\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        identity = x.clone()  # 入力を保持する\n",
    "\n",
    "        x = self.conv1(x)  # 1×1の畳み込み\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)  # 3×3の畳み込み（パターン3の時はstrideが2になるため、ここでsizeが半分になる）\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv3(x)  # 1×1の畳み込み\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        # 必要な場合はconv層（1×1）を通してidentityのchannel数の調整してから足す\n",
    "        if self.identity_conv is not None:\n",
    "            identity = self.identity_conv(identity)\n",
    "        x += identity\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "#  Resnet50\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self,block):\n",
    "        super(ResNet,self).__init__()\n",
    "\n",
    "        # conv1はアーキテクチャ通りにベタ打ち\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) # in:(64,112*112)、out:(64,56*56)\n",
    "        self.maxpool = nn.Identity()\n",
    "\n",
    "        # conv2_xはサイズの変更は不要のため、strideは1\n",
    "        self.conv2_x = self._make_layer(block, 3, res_block_in_channels=64, first_conv_out_channels=64, stride=1)\n",
    "\n",
    "        # conv3_x以降はサイズの変更をする必要があるため、strideは2\n",
    "        self.conv3_x = self._make_layer(block, 4, res_block_in_channels=256,  first_conv_out_channels=128, stride=2)\n",
    "        self.conv4_x = self._make_layer(block, 6, res_block_in_channels=512,  first_conv_out_channels=256, stride=2)\n",
    "        self.conv5_x = self._make_layer(block, 3, res_block_in_channels=1024, first_conv_out_channels=512, stride=2)\n",
    "\n",
    "        #self.avgpool = nn.AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        # self.fc1 = nn.Linear(512*4,2)\n",
    "        self.fc1 = nn.Identity()\n",
    "    \n",
    "        # mlp projection head\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(in_features=2048, out_features=2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=2048, out_features=128),\n",
    "            nn.BatchNorm1d(128),\n",
    "        )\n",
    "        # Regression\n",
    "        self.regression = nn.Sequential(\n",
    "            nn.Linear(2048, 512), \n",
    "            nn.LeakyReLU(),       \n",
    "            nn.Linear(512, 128),  \n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 32),        \n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.conv1(x)  \n",
    "        x = self.bn1(x)     \n",
    "        x = self.relu(x)    \n",
    "        x = self.maxpool(x) #out:(64*16*16)\n",
    "        \n",
    "\n",
    "        x = self.conv2_x(x)  # in:(64,56*56)  、out:(256,56*56)\n",
    "        x = self.conv3_x(x)  # in:(256,56*56) 、out:(512,28*28)\n",
    "        x = self.conv4_x(x)  # in:(512,28*28) 、out:(1024,14*14)\n",
    "        x = self.conv5_x(x)  # in:(1024,14*14)、out:(2048,7*7)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1) # 2048\n",
    "        x = self.fc1(x)\n",
    "        #backbone_output = x.clone()\n",
    "\n",
    "        projection_output = self.projection(x)\n",
    "        regression_output = self.regression(x)\n",
    "\n",
    "        return projection_output, regression_output\n",
    "\n",
    "    def _make_layer(self, block, num_res_blocks, res_block_in_channels, first_conv_out_channels, stride):\n",
    "        layers = []\n",
    "\n",
    "        # 1つ目の残差ブロックではchannel調整、及びsize調整が発生する\n",
    "        # identifyを足す前に1×1のconv層を追加し、サイズ調整が必要な場合はstrideを2に設定\n",
    "        identity_conv = nn.Conv2d(res_block_in_channels, first_conv_out_channels*4, kernel_size=1,stride=stride)\n",
    "        layers.append(block(res_block_in_channels, first_conv_out_channels, identity_conv, stride))\n",
    "\n",
    "        # 2つ目以降のinput_channel数は1つ目のoutput_channelの4倍\n",
    "        in_channels = first_conv_out_channels*4\n",
    "\n",
    "        # channel調整、size調整は発生しないため、identity_convはNone、strideは1\n",
    "        for i in range(num_res_blocks - 1):\n",
    "            layers.append(block(in_channels, first_conv_out_channels, identity_conv=None, stride=1))\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similar matrix 🎭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 類似行列\n",
    "def sim_matrix(output1:torch.tensor, output2:torch.tensor):\n",
    "\n",
    "    \"\"\"\n",
    "    Attributes\n",
    "    ----------\n",
    "    output1 : torch.tensor\n",
    "        ネットワークの出力前半\n",
    "    output2 : torch.tensor\n",
    "        ネットワークの出力後半\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    sim : torch.tensor\n",
    "        類似行列\n",
    "    \"\"\"   \n",
    "    # 実は2つに分ける意味ない\n",
    "    zi_norm = F.normalize(output1, dim=1)\n",
    "    zj_norm = F.normalize(output2, dim=1)\n",
    "    representation = torch.cat([zi_norm,zj_norm], dim=0)\n",
    "    sim = torch.matmul(representation, torch.t(representation))\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function 🌈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast_loss_function(sim, ds, device, args=args):\n",
    "    harf_batch_size = int(args.batch_size/2)\n",
    "\n",
    "    # 行列全体にexp(./tau)をかける\n",
    "    sim = torch.exp(sim/args.tau)\n",
    "    \n",
    "    # 重み\n",
    "    # 空気揺らぎ量の差\n",
    "    ds = ds.to(torch.float)\n",
    "    matrix1 = ds.repeat(args.batch_size,1)\n",
    "    matrix2 = matrix1.T\n",
    "    weight = torch.abs(matrix2 - matrix1)\n",
    "    # たまたま揺らぎ量が重複する場合，0の要素を1に変換します.\n",
    "    weight[weight == 0] = 1\n",
    "    # 指数にする\n",
    "    weight = torch.exp(weight/args.tau2)\n",
    "    # 指示関数\n",
    "    mask = (~torch.eye(args.batch_size, args.batch_size, dtype=bool)).float()\n",
    "    weight = weight * mask\n",
    "    weight = weight.to(device)\n",
    "    bottom = weight*sim\n",
    "\n",
    "    #対角成分を抽出　positive pairを抽出\n",
    "    sim_ij = torch.diag(bottom, harf_batch_size)\n",
    "    sim_ji = torch.diag(bottom, -harf_batch_size)\n",
    "    top = torch.cat([sim_ij, sim_ji], dim=0)\n",
    "\n",
    "    all_losses = - torch.log(top/torch.sum(bottom, dim = 1))\n",
    "    loss = torch.sum(all_losses)/ args.batch_size\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressison_loss_function(output, labels, args=args):\n",
    "    criterion = nn.MSELoss()\n",
    "    loss = args.gamma * criterion(output, labels) / args.batch_size\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train 🏋️‍♂️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloaders_dict, device, opt, writer, earlystopping):\n",
    "\n",
    "    #global epoch\n",
    "\n",
    "    BREAK = False\n",
    "    print(f\"\\nStarting training\")\n",
    "    for epoch in range(0, args.epochs+1):\n",
    "\n",
    "        # epochごとの学習と検証のループ\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # モデルを訓練モードに\n",
    "            else:\n",
    "                model.eval()   # モデルを検証モードに\n",
    "\n",
    "            epoch_loss = 0.0  # epochの損失和\n",
    "            epoch_contrast_loss = 0.0\n",
    "            epoch_regression_loss = 0.0                \n",
    "\n",
    "            #未訓練時の性能評価\n",
    "            if (epoch == 0 and phase=='train'):\n",
    "                continue\n",
    "            \n",
    "            # データローダーからミニバッチを取り出すループ。args['batch_size']枚ごと取り出す\n",
    "            for inputs, labels, ds in tqdm(dataloaders_dict[phase], leave=False, desc='Epoch {}/{} {}'.format(epoch, args.epochs, phase)): \n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # optimizerを初期化\n",
    "                opt.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    projection_output, regression_output = model(inputs)\n",
    "                    output1, output2 = torch.chunk(projection_output, chunks=2, dim=0)\n",
    "                    sim = sim_matrix(output1, output2)\n",
    "                    contrast_loss = contrast_loss_function(sim, ds, device)\n",
    "                    regression_loss = regressison_loss_function(regression_output, labels)\n",
    "                    loss = contrast_loss + regression_loss\n",
    "\n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward() \n",
    "                        opt.step()\n",
    "\n",
    "                # 損失の計算\n",
    "                epoch_loss += loss.item()\n",
    "                epoch_contrast_loss += contrast_loss.item()\n",
    "                epoch_regression_loss += regression_loss.item()\n",
    "\n",
    "            #tensorboardに出力\n",
    "            if phase == 'train':\n",
    "                writer.add_scalar('train_epoch_loss', epoch_loss, epoch) #(グラフ名, y座標, x座標) \n",
    "                writer.add_scalar('train_contrast_epoch_loss', epoch_contrast_loss, epoch)    \n",
    "                writer.add_scalar('train_epoch_regression_loss', epoch_regression_loss, epoch)           \n",
    "            elif phase == 'valid':\n",
    "                writer.add_scalar('valid_epoch_loss', epoch_loss, epoch)\n",
    "                writer.add_scalar('valid_contrast_epoch_loss', epoch_contrast_loss, epoch)    \n",
    "                writer.add_scalar('valid_epoch_regression_loss', epoch_regression_loss, epoch)                 \n",
    "                #毎エポックearlystoppingの判定をさせる\n",
    "                earlystopping(epoch_loss, model) #callメソッド呼び出し\n",
    "                if earlystopping.early_stop: #ストップフラグがTrueの場合、breakでforループを抜ける\n",
    "                    print(\"Early Stopping!\")\n",
    "                    BREAK = True\n",
    "        if BREAK:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EarlyStopping ⛔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    earlystoppingクラス\n",
    "    損失が下がったことを判断して学習を打ち切る\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    patience : int\n",
    "        何回損失が下がらなかったら学習を打ち切るか\n",
    "    verbose : bool\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience, verbose):\n",
    "        \"\"\"引数 : 最小値の非更新数カウンタ、表示設定\"\"\"\n",
    "\n",
    "        self.patience = patience    #設定ストップカウンタ\n",
    "        self.verbose = verbose      #表示の有無\n",
    "        self.counter = 0            #現在のカウンタ値\n",
    "        self.best_score = None      #ベストスコア\n",
    "        self.early_stop = False     #ストップフラグ\n",
    "        self.val_loss_min = np.Inf   #前回のベストスコア記憶用\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        \"\"\"\n",
    "        特殊(call)メソッド\n",
    "        実際に学習ループ内で最小lossを更新したか否かを計算させる部分\n",
    "        \"\"\"\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:  #1Epoch目の処理\n",
    "            self.best_score = score   #1Epoch目はそのままベストスコアとして記録する\n",
    "            self.checkpoint(val_loss, model)  #記録後にモデルを保存してスコア表示する\n",
    "        elif score < self.best_score:  # ベストスコアを更新できなかった場合\n",
    "            self.counter += 1   #ストップカウンタを+1\n",
    "            # if self.verbose:  #表示を有効にした場合は経過を表示\n",
    "            #     print(f'EarlyStopping counter: {self.counter} out of {self.patience}')  #現在のカウンタを表示する \n",
    "            if self.counter >= self.patience:  #設定カウントを上回ったらストップフラグをTrueに変更\n",
    "                self.early_stop = True\n",
    "        else:  #ベストスコアを更新した場合\n",
    "            self.best_score = score  #ベストスコアを上書き\n",
    "            self.checkpoint(val_loss, model)  #モデルを保存してスコア表示\n",
    "            self.counter = 0  #ストップカウンタリセット\n",
    "\n",
    "    def checkpoint(self, val_loss, model):\n",
    "        '''ベストスコア更新時に実行されるチェックポイント関数'''\n",
    "        if self.verbose:  #表示を有効にした場合は、前回のベストスコアからどれだけ更新したか？を表示\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        save_path = os.path.join(args.model_save_path, f'{args.model_file_name}.pth')\n",
    "        torch.save(model.state_dict(), save_path)  #ベストモデルを指定したpathに保存\n",
    "        self.val_loss_min = val_loss  #その時のlossを記録する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Main 🏃‍♀️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check GPU\n",
      "You can use GPU(NVIDIA GeForce RTX 3090)\n",
      "-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 5625.198720).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (5625.198720 --> 4910.085599).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4910.085599 --> 4907.389169).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4907.389169 --> 4889.638279).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4889.638279 --> 4889.463548).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4889.463548 --> 4873.651827).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4873.651827 --> 4867.343175).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4867.343175 --> 4861.617738).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4861.617738 --> 4839.588843).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4839.588843 --> 4832.111764).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4832.111764 --> 4806.198966).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4806.198966 --> 4801.864892).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4801.864892 --> 4794.575014).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4794.575014 --> 4785.322016).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4785.322016 --> 4768.661429).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4768.661429 --> 4751.131589).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4751.131589 --> 4735.666577).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4735.666577 --> 4726.380434).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4726.380434 --> 4719.337009).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4719.337009 --> 4700.149067).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4700.149067 --> 4692.345592).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4692.345592 --> 4653.800603).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4653.800603 --> 4644.607992).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4644.607992 --> 4644.354204).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (4644.354204 --> 4639.106564).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# 時間計測開始\n",
    "time_start = time.time()\n",
    "\n",
    "#GPU\n",
    "device = check_GPU()\n",
    "\n",
    "os.makedirs(args.model_save_path, exist_ok=True) #重みファイルの保存ディレクトリ\n",
    "# 学習条件の保存\n",
    "csv_file = os.path.join(args.model_save_path,f\"{args.model_file_name}_info.csv\")\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    saver = csv.writer(file)\n",
    "    # ヘッダー（辞書のキー）を書き込む\n",
    "    saver.writerow(args.keys())\n",
    "    # データ（辞書の値）を書き込む\n",
    "    saver.writerow(args.values())\n",
    "\n",
    "\n",
    "#train test split  \n",
    "#dataset_dict = image_label_collector()\n",
    "    \n",
    "train_size = find_closest_divisible(args.train_size, int(args.batch_size))\n",
    "valid_size = find_closest_divisible(args.valid_size, int(args.batch_size))\n",
    "\n",
    "# Quick start (train test splitをコメントアウトして使う)\n",
    "train_df = pd.read_csv(\"train.csv\")[:train_size]\n",
    "valid_df = pd.read_csv(\"valid.csv\")[:valid_size]\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "dataset_dict = {\n",
    "        \"train\":train_df,\n",
    "        \"valid\":valid_df,\n",
    "        \"test\":test_df\n",
    "    }\n",
    "\n",
    "#画像の標準化\n",
    "mean, std = image_normalization(dataset_dict[\"train\"])\n",
    "\n",
    "transform = ImageTransform(mean, std)\n",
    "\n",
    "#logger\n",
    "writer = tbx.SummaryWriter()\n",
    "\n",
    "# Dataset\n",
    "train_dataset = Image_Dataset(df=dataset_dict[\"train\"], transform=transform, phase='train') \n",
    "valid_dataset = Image_Dataset(df=dataset_dict[\"valid\"], transform=transform, phase='valid')\n",
    "\n",
    "# make dataloader\n",
    "train_dataloader=torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    "    )\n",
    "\n",
    "valid_dataloader=torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    "    )\n",
    "\n",
    "# 辞書型変数にまとめる\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"valid\": valid_dataloader}          \n",
    "\n",
    "#Network\n",
    "model = ResNet(block)\n",
    "model.to(device)\n",
    "\n",
    "#optimizer\n",
    "opt = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "#early topping \n",
    "earlystopping = EarlyStopping(patience=args.early_stop_patience, verbose=True) \n",
    "\n",
    "#train\n",
    "train(model, dataloaders_dict, device, opt, writer, earlystopping)\n",
    "\n",
    "writer.close()\n",
    "\n",
    "#時間計測終了\n",
    "time_end = time.time()\n",
    "#経過時間（秒）\n",
    "elapsed = time_end - time_start\n",
    "#秒➡時間\n",
    "td = datetime.timedelta(seconds=elapsed)\n",
    "#経過時間記憶\n",
    "f = open('elapsed_time.txt','a')\n",
    "f.write(f\"{args.model_file_name}.pth : {str(td)} ,\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   \n",
    "    　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　{ヽﾐ∧\n",
    "    　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　 　 彡彡 　 .＼\n",
    "    　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　 　 彡彡　　　 .● ヽ\n",
    "    　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　 彡　　 （　　　　＼\n",
    "    　　　　　　　　　　　　　　　　 ＿───────────＿＿＿＿──../　             /ヽ 　 ヽ　　 ／￣￣￣￣￣￣￣￣\n",
    "    　　　　　　　　　　　　　　　／　　　 　 　 /　 　 　 ./　　　　　　 　 ./　　ヽ　o丿　＜　ワープに使ってください\n",
    "    　 　 　 　 　 　 　 彡彡彡　 　 　 　 　 ./　　　　　/　　　　　 　 　  │ 　 　 　 　 　＼＿＿＿＿＿＿＿＿\n",
    "    　　 　 　 　 　 彡彡彡彡　　　 　 　 　  |ｺﾞｰﾙﾄﾞｼｯﾌﾟ/　　　　　　 　 　 │\n",
    "    　　 　 　 彡彡彡　　　 /　　　　　　　 ..￣￣￣￣￣　 .ヽ、　 　 　 ヽ　ﾉ\n",
    "    　　 　 彡彡　　　　 　 ﾉ　 　 　 ／￣￣｀ ヽ ､　　 　 　 　 ｀､　　 　 ﾉ　＼\n",
    "    　　　 彡　　　　　　 ／　　 ／　｀､　　　／　　 ｀　ー ､ ＿＿ヽ　　 ヽ　 　  ヽ 、\n",
    "    　　　　　 　 　 　 ／ 　 ／　　　 /　　 /　　　　　　　　 　 　 　 ＼　 丶　- ､ ｀､\n",
    "    　　　　　　　　　/　.／　　　　／ 　 ／　　　　　　　　　　　　　　　 ＼　｀､　　＼＼\n",
    "    　　　　 　 　 .／.／　　　　　 |　　/　　　　　　　　　　　　　　　 　  ＼ 丶 　 　ヽ ヽ\n",
    "    　　　 　 ___／.／　 　 　 　 　 |　|　　　　　　　　　　　　　　　　　　　ヽ｀､ 　 　｀､｀､\n",
    "    　　　　/ |__／　　　　　　　　　 | |　　　　　　　　　　　　　　　　　　　　｀､ヽ、　　 ｔﾆゝ\n",
    "    　　 　 ￣　　 　 　 　 　 　 \"\"\"\"''\"\"'\"\" 　　　　　　　　　　　　　 　 　 　 ヽ ､ヽ　　　\n",
    "    　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　 　 　 　 　 　 ｔﾆゝ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のコマンドをターミナルに入力して，ログを見る  \n",
    "conda activate env_pytorch  \n",
    "tensorboard --logdir runs  \n",
    "終わるとき➡ctrlキーとcを同時に入力  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
