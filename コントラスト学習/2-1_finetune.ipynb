{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries 📚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import easydict\n",
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.utils.data as data\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "from glob import glob\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "import tensorboardX as tbx\n",
    "import csv\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random seed🌱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#再現性の確保\n",
    "seed = 44\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    #Disabling the benchmark by CUDA convolution operation(GPUを使うときの再現性の担保) (https://pytorch.org/docs/stable/notes/randomness.html)\n",
    "    torch.backends.cudnn.benchmark = False \n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments 📗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"batch_size\":32, # 分割数＝batch_size/2\n",
    "    \"epochs\":100000,\n",
    "    \"learning_rate\" : 0.00001, # 損失が下がりきらない場合は下げるといいかも？　adamのデフォルト0.001\n",
    "    \"early_stop_patience\" : 15,\n",
    "    \n",
    "    \"model_save_path\" : \"Checkpoints\",\n",
    "    \"load_model_file_name\" : \"model_data40000\",\n",
    "    \"save_model_file_name\" : \"model_data40000_finetuned\",\n",
    "\n",
    "    \"train_size\" : 40000,\n",
    "    \"valid_size\" : 10000\n",
    "    \n",
    "    #\"gamma\" : 1, #回帰損失を重視する割合\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU 📺"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_GPU():\n",
    "    \"\"\"\n",
    "    使用するデバイスを出力する関数\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    device : object\n",
    "        GPUが使えるなら'cuda:0',使えないなら'cpu'を返す\n",
    "    \"\"\"\n",
    "    print(\"Check GPU\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"You can use GPU({torch.cuda.get_device_name()})\")\n",
    "        d_type = \"cuda:0\"\n",
    "    else:\n",
    "        print(\"You use cpu\")\n",
    "        d_type = \"cpu\"\n",
    "    print(\"-----\")\n",
    "    device = torch.device(d_type)\n",
    "    return device "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image & Label 📂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_divisible(a:int, b:int):\n",
    "    \"\"\"\n",
    "    バッチサイズで割り切れるデータ数を求めるための関数\n",
    "    \"\"\"\n",
    "    remainder = a % b\n",
    "    if remainder == 0:\n",
    "        return int(a)  # aはすでにbで割り切れる\n",
    "    elif remainder >= b / 2:\n",
    "        return int(a + (b - remainder))  # aを増やしてbの次の倍数にする\n",
    "    else:\n",
    "        return int(a - remainder)  # aを減らしてbの現在の倍数にする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization 📊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_normalization():\n",
    "    \"\"\"\n",
    "    平均値，標準偏差を求める\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mean : tuple\n",
    "        データセットの画素の平均\n",
    "    std : tuple\n",
    "        データセットの画素の標準偏差\n",
    "    \"\"\"\n",
    "    df_ms = pd.read_csv(f\"mean_std.csv\")\n",
    "    mean = df_ms[\"mean\"][0]\n",
    "    std = df_ms[\"std\"][0]\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data set 🧰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform:\n",
    "    \"\"\"\n",
    "    画像の前処理クラス\n",
    "    訓練時だけ、データオーギュメンテーション(DA)ができるように、train,validで分けて書いた\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    mean : int\n",
    "        データセットの画素値の平均値\n",
    "    std : int\n",
    "        データセットの画素値の標準偏差\n",
    "    \"\"\"   \n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        self.data_transform = {\n",
    "            'train':transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std) \n",
    "            ]),\n",
    "            'valid':transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ])\n",
    "        }\n",
    "    \n",
    "    #引数なしで呼ばれたときの挙動を定義\n",
    "    def __call__(self, img, phase='train'):\n",
    "        return self.data_transform[phase](img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_Dataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    画像のデータセットクラス。\n",
    "    Pytorch Dataset class を継承\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    file_list : list\n",
    "        画像のpath_list\n",
    "    label_list : list\n",
    "        ラベルのpath_list       \n",
    "    transform : object\n",
    "        class ImageTransform()    \n",
    "    phase : str\n",
    "        'train' or 'valid'\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, transform, phase='train'):\n",
    "        self.file_list = df[\"fname\"] \n",
    "        self.labels = df[[\"dx\",\"dy\"]].to_numpy()\n",
    "        #self.l = df[\"l\"]\n",
    "        self.d = df[\"d\"]\n",
    "        self.transform = transform  \n",
    "        self.phase = phase  \n",
    "\n",
    "    #このクラスの画像枚数を定義。\n",
    "    def __len__(self):\n",
    "        return len(self.file_list) \n",
    "\n",
    "    #このクラスに角括弧でアクセスした時の挙動を定義\n",
    "    def __getitem__(self, index):\n",
    "        # 画像をロード\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path)\n",
    "        #img = img.convert(\"L\") #グレイスケール \n",
    "        # 前処理\n",
    "        img_transformed = self.transform(\n",
    "            img, self.phase)  # torch.Size([width, height]) \n",
    "\n",
    "        #label\n",
    "        label = self.labels[index]\n",
    "        #Tensorに変換\n",
    "        label = torch.tensor(label, dtype=torch.float32) \n",
    "\n",
    "        # 空気揺らぎ量\n",
    "        d = self.d[index]           \n",
    "\n",
    "        return img_transformed, label, d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetWork 🧠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデル\n",
    "\n",
    "# # 残差ブロック\n",
    "class block(nn.Module):\n",
    "    def __init__(self, first_conv_in_channels, first_conv_out_channels, identity_conv=None, stride=1):\n",
    "        \"\"\"\n",
    "        残差ブロックを作成するクラス\n",
    "        Args:\n",
    "            first_conv_in_channels : 1番目のconv層（1×1）のinput channel数\n",
    "            first_conv_out_channels : 1番目のconv層（1×1）のoutput channel数\n",
    "            identity_conv : channel数調整用のconv層\n",
    "            stride : 3×3conv層におけるstide数。sizeを半分にしたいときは2に設定\n",
    "        \"\"\"        \n",
    "        super(block, self).__init__()\n",
    "\n",
    "        # 1番目のconv層（1×1）\n",
    "        self.conv1 = nn.Conv2d(first_conv_in_channels, first_conv_out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(first_conv_out_channels)\n",
    "\n",
    "        # 2番目のconv層（3×3）\n",
    "        # パターン3の時はsizeを変更できるようにstrideは可変\n",
    "        self.conv2 = nn.Conv2d(first_conv_out_channels, first_conv_out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(first_conv_out_channels)\n",
    "\n",
    "        # 3番目のconv層（1×1）\n",
    "        # output channelはinput channelの4倍になる\n",
    "        self.conv3 = nn.Conv2d(first_conv_out_channels, first_conv_out_channels*4, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(first_conv_out_channels*4)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # identityのchannel数の調整が必要な場合はconv層（1×1）を用意、不要な場合はNone\n",
    "        self.identity_conv = identity_conv\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        identity = x.clone()  # 入力を保持する\n",
    "\n",
    "        x = self.conv1(x)  # 1×1の畳み込み\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)  # 3×3の畳み込み（パターン3の時はstrideが2になるため、ここでsizeが半分になる）\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv3(x)  # 1×1の畳み込み\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        # 必要な場合はconv層（1×1）を通してidentityのchannel数の調整してから足す\n",
    "        if self.identity_conv is not None:\n",
    "            identity = self.identity_conv(identity)\n",
    "        x += identity\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "#  Resnet50\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self,block):\n",
    "        super(ResNet,self).__init__()\n",
    "\n",
    "        # conv1はアーキテクチャ通りにベタ打ち\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) # in:(64,112*112)、out:(64,56*56)\n",
    "        self.maxpool = nn.Identity()\n",
    "\n",
    "        # conv2_xはサイズの変更は不要のため、strideは1\n",
    "        self.conv2_x = self._make_layer(block, 3, res_block_in_channels=64, first_conv_out_channels=64, stride=1)\n",
    "\n",
    "        # conv3_x以降はサイズの変更をする必要があるため、strideは2\n",
    "        self.conv3_x = self._make_layer(block, 4, res_block_in_channels=256,  first_conv_out_channels=128, stride=2)\n",
    "        self.conv4_x = self._make_layer(block, 6, res_block_in_channels=512,  first_conv_out_channels=256, stride=2)\n",
    "        self.conv5_x = self._make_layer(block, 3, res_block_in_channels=1024, first_conv_out_channels=512, stride=2)\n",
    "\n",
    "        #self.avgpool = nn.AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        # self.fc1 = nn.Linear(512*4,2)\n",
    "        self.fc1 = nn.Identity()\n",
    "    \n",
    "        # mlp projection head\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(in_features=2048, out_features=2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=2048, out_features=128),\n",
    "            nn.BatchNorm1d(128),\n",
    "        )\n",
    "        # Regression\n",
    "        self.regression = nn.Sequential(\n",
    "            nn.Linear(2048, 512), \n",
    "            nn.LeakyReLU(),       \n",
    "            nn.Linear(512, 128),  \n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 32),        \n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.conv1(x)  \n",
    "        x = self.bn1(x)     \n",
    "        x = self.relu(x)    \n",
    "        x = self.maxpool(x) #out:(64*16*16)\n",
    "        \n",
    "\n",
    "        x = self.conv2_x(x)  # in:(64,56*56)  、out:(256,56*56)\n",
    "        x = self.conv3_x(x)  # in:(256,56*56) 、out:(512,28*28)\n",
    "        x = self.conv4_x(x)  # in:(512,28*28) 、out:(1024,14*14)\n",
    "        x = self.conv5_x(x)  # in:(1024,14*14)、out:(2048,7*7)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1) # 2048\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        #projection_output = self.projection(backbone_output)\n",
    "        regression_output = self.regression(x)\n",
    "\n",
    "        return regression_output\n",
    "\n",
    "    def _make_layer(self, block, num_res_blocks, res_block_in_channels, first_conv_out_channels, stride):\n",
    "        layers = []\n",
    "\n",
    "        # 1つ目の残差ブロックではchannel調整、及びsize調整が発生する\n",
    "        # identifyを足す前に1×1のconv層を追加し、サイズ調整が必要な場合はstrideを2に設定\n",
    "        identity_conv = nn.Conv2d(res_block_in_channels, first_conv_out_channels*4, kernel_size=1,stride=stride)\n",
    "        layers.append(block(res_block_in_channels, first_conv_out_channels, identity_conv, stride))\n",
    "\n",
    "        # 2つ目以降のinput_channel数は1つ目のoutput_channelの4倍\n",
    "        in_channels = first_conv_out_channels*4\n",
    "\n",
    "        # channel調整、size調整は発生しないため、identity_convはNone、strideは1\n",
    "        for i in range(num_res_blocks - 1):\n",
    "            layers.append(block(in_channels, first_conv_out_channels, identity_conv=None, stride=1))\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train 🏋️‍♂️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloaders_dict, device, opt, criterion, writer, earlystopping): #くわーぐす\n",
    "\n",
    "    #global epoch\n",
    "\n",
    "    BREAK = False\n",
    "    print(f\"\\nStarting training\")\n",
    "    for epoch in range(0, args.epochs+1):\n",
    "\n",
    "        # epochごとの学習と検証のループ\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # モデルを訓練モードに\n",
    "            else:\n",
    "                model.eval()   # モデルを検証モードに\n",
    "\n",
    "            epoch_loss = 0.0  # epochの損失和              \n",
    "\n",
    "            #未訓練時の性能評価\n",
    "            if (epoch == 0 and phase=='train'):\n",
    "                continue\n",
    "            \n",
    "            # データローダーからミニバッチを取り出すループ。args['batch_size']枚ごと取り出す\n",
    "            for inputs, labels, _ in tqdm(dataloaders_dict[phase], leave=False, desc='Epoch {}/{} {}'.format(epoch, args.epochs, phase)): \n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # optimizerを初期化\n",
    "                opt.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)  # 損失を計算。\n",
    "\n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward() \n",
    "                        opt.step()\n",
    "\n",
    "                # 損失の計算\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            #tensorboardに出力\n",
    "            if phase == 'train':\n",
    "                writer.add_scalar('train_epoch_loss_finetune', epoch_loss, epoch) #(グラフ名, y座標, x座標)           \n",
    "            elif phase == 'valid':\n",
    "                writer.add_scalar('valid_epoch_loss_finetune', epoch_loss, epoch)                 \n",
    "                #毎エポックearlystoppingの判定をさせる\n",
    "                earlystopping(epoch_loss, model) #callメソッド呼び出し\n",
    "                if earlystopping.early_stop: #ストップフラグがTrueの場合、breakでforループを抜ける\n",
    "                    print(\"Early Stopping!\")\n",
    "                    BREAK = True\n",
    "        if BREAK:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EarlyStopping ⛔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    earlystoppingクラス\n",
    "    損失が下がったことを判断して学習を打ち切る\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    patience : int\n",
    "        何回損失が下がらなかったら学習を打ち切るか\n",
    "    verbose : bool\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience, verbose):\n",
    "        \"\"\"引数 : 最小値の非更新数カウンタ、表示設定\"\"\"\n",
    "\n",
    "        self.patience = patience    #設定ストップカウンタ\n",
    "        self.verbose = verbose      #表示の有無\n",
    "        self.counter = 0            #現在のカウンタ値\n",
    "        self.best_score = None      #ベストスコア\n",
    "        self.early_stop = False     #ストップフラグ\n",
    "        self.val_loss_min = np.Inf   #前回のベストスコア記憶用\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        \"\"\"\n",
    "        特殊(call)メソッド\n",
    "        実際に学習ループ内で最小lossを更新したか否かを計算させる部分\n",
    "        \"\"\"\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:  #1Epoch目の処理\n",
    "            self.best_score = score   #1Epoch目はそのままベストスコアとして記録する\n",
    "            self.checkpoint(val_loss, model)  #記録後にモデルを保存してスコア表示する\n",
    "        elif score < self.best_score:  # ベストスコアを更新できなかった場合\n",
    "            self.counter += 1   #ストップカウンタを+1\n",
    "            # if self.verbose:  #表示を有効にした場合は経過を表示\n",
    "            #     print(f'EarlyStopping counter: {self.counter} out of {self.patience}')  #現在のカウンタを表示する \n",
    "            if self.counter >= self.patience:  #設定カウントを上回ったらストップフラグをTrueに変更\n",
    "                self.early_stop = True\n",
    "        else:  #ベストスコアを更新した場合\n",
    "            self.best_score = score  #ベストスコアを上書き\n",
    "            self.checkpoint(val_loss, model)  #モデルを保存してスコア表示\n",
    "            self.counter = 0  #ストップカウンタリセット\n",
    "\n",
    "    def checkpoint(self, val_loss, model):\n",
    "        '''ベストスコア更新時に実行されるチェックポイント関数'''\n",
    "        if self.verbose:  #表示を有効にした場合は、前回のベストスコアからどれだけ更新したか？を表示\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        save_path = os.path.join(args.model_save_path, f'{args.save_model_file_name}.pth')\n",
    "        torch.save(model.state_dict(), save_path)  #ベストモデルを指定したpathに保存\n",
    "        self.val_loss_min = val_loss  #その時のlossを記録する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Main 🏃‍♀️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check GPU\n",
      "You can use GPU(NVIDIA GeForce RTX 3090)\n",
      "-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weight from Checkpoints\\model_data40000.pth\n",
      "\n",
      "Starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 324.218360).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (324.218360 --> 169.036024).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (169.036024 --> 152.326215).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (152.326215 --> 131.481030).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (131.481030 --> 126.552311).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (126.552311 --> 117.718289).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (117.718289 --> 115.689377).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (115.689377 --> 110.436106).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (110.436106 --> 105.967190).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (105.967190 --> 93.573546).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (93.573546 --> 93.209206).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (93.209206 --> 90.725541).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (90.725541 --> 84.421769).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (84.421769 --> 83.112951).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (83.112951 --> 81.272874).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (81.272874 --> 81.270854).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (81.270854 --> 80.083955).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (80.083955 --> 78.692370).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (78.692370 --> 75.740050).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (75.740050 --> 74.847233).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (74.847233 --> 73.263275).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (73.263275 --> 72.771022).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (72.771022 --> 72.106287).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (72.106287 --> 71.147281).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (71.147281 --> 70.097331).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (70.097331 --> 68.078625).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (68.078625 --> 66.090409).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (66.090409 --> 65.094765).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (65.094765 --> 63.888591).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (63.888591 --> 63.498827).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (63.498827 --> 63.204927).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (63.204927 --> 61.825383).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (61.825383 --> 61.502147).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (61.502147 --> 60.804119).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (60.804119 --> 59.493612).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (59.493612 --> 58.888947).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (58.888947 --> 58.275970).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# 時間計測開始\n",
    "time_start = time.time()\n",
    "\n",
    "#GPU\n",
    "device = check_GPU()\n",
    "\n",
    "os.makedirs(args.model_save_path, exist_ok=True) #重みファイルの保存ディレクトリ\n",
    "# 学習条件の保存\n",
    "csv_file = os.path.join(args.model_save_path,f\"{args.save_model_file_name}_info.csv\")\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    saver = csv.writer(file)\n",
    "    # ヘッダー（辞書のキー）を書き込む\n",
    "    saver.writerow(args.keys())\n",
    "    # データ（辞書の値）を書き込む\n",
    "    saver.writerow(args.values())\n",
    "\n",
    "\n",
    "# #train test split  \n",
    "# dataset_dict = image_label_collector()\n",
    "\n",
    "train_size = find_closest_divisible(args.train_size, int(args.batch_size))\n",
    "valid_size = find_closest_divisible(args.valid_size, int(args.batch_size))\n",
    "\n",
    "# Quick start (train test splitをコメントアウトして使う)\n",
    "train_df = pd.read_csv(\"train.csv\")[:train_size]\n",
    "valid_df = pd.read_csv(\"valid.csv\")[:valid_size]\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "dataset_dict = {\n",
    "        \"train\":train_df,\n",
    "        \"valid\":valid_df,\n",
    "        \"test\":test_df\n",
    "    }\n",
    "\n",
    "#画像の標準化\n",
    "mean, std = image_normalization()\n",
    "\n",
    "transform = ImageTransform(mean, std)\n",
    "\n",
    "#logger\n",
    "writer = tbx.SummaryWriter()\n",
    "\n",
    "# Dataset\n",
    "train_dataset = Image_Dataset(df=dataset_dict[\"train\"], transform=transform, phase='train') \n",
    "valid_dataset = Image_Dataset(df=dataset_dict[\"valid\"], transform=transform, phase='valid')\n",
    "\n",
    "# make dataloader\n",
    "train_dataloader=torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    pin_memory=True,\n",
    "    shuffle=True, # 訓練時とは違いランダムにした\n",
    "    )\n",
    "\n",
    "valid_dataloader=torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    "    )\n",
    "\n",
    "# 辞書型変数にまとめる\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"valid\": valid_dataloader}          \n",
    "\n",
    "#Network\n",
    "model = ResNet(block)\n",
    "# load weights\n",
    "load_path = os.path.join(args.model_save_path,args.load_model_file_name+\".pth\")\n",
    "model.load_state_dict(torch.load(load_path))\n",
    "print(f\"Loaded weight from {load_path}\")\n",
    "model.to(device)\n",
    "\n",
    "#criterion\n",
    "criterion = torch.nn.MSELoss()\n",
    "#optimizer\n",
    "opt = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "#early topping \n",
    "earlystopping = EarlyStopping(patience=args.early_stop_patience, verbose=True) \n",
    "\n",
    "#train\n",
    "train(model, dataloaders_dict, device, opt, criterion, writer, earlystopping)\n",
    "\n",
    "writer.close()\n",
    "\n",
    "#時間計測終了\n",
    "time_end = time.time()\n",
    "#経過時間（秒）\n",
    "elapsed = time_end - time_start\n",
    "#秒➡時間\n",
    "td = datetime.timedelta(seconds=elapsed)\n",
    "#経過時間記憶\n",
    "f = open('elapsed_time.txt','a')\n",
    "f.write(f\"{args.save_model_file_name}.pth : {str(td)} ,\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   \n",
    "    　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　{ヽﾐ∧\n",
    "    　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　 　 彡彡 　 .＼\n",
    "    　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　 　 彡彡　　　 .● ヽ\n",
    "    　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　 彡　　 （　　　　＼\n",
    "    　　　　　　　　　　　　　　　　 ＿───────────＿＿＿＿──../　             /ヽ 　 ヽ　　 ／￣￣￣￣￣￣￣￣\n",
    "    　　　　　　　　　　　　　　　／　　　 　 　 /　 　 　 ./　　　　　　 　 ./　　ヽ　o丿　＜　ワープに使ってください\n",
    "    　 　 　 　 　 　 　 彡彡彡　 　 　 　 　 ./　　　　　/　　　　　 　 　  │ 　 　 　 　 　＼＿＿＿＿＿＿＿＿\n",
    "    　　 　 　 　 　 彡彡彡彡　　　 　 　 　  |ｺﾞｰﾙﾄﾞｼｯﾌﾟ/　　　　　　 　 　 │\n",
    "    　　 　 　 彡彡彡　　　 /　　　　　　　 ..￣￣￣￣￣　 .ヽ、　 　 　 ヽ　ﾉ\n",
    "    　　 　 彡彡　　　　 　 ﾉ　 　 　 ／￣￣｀ ヽ ､　　 　 　 　 ｀､　　 　 ﾉ　＼\n",
    "    　　　 彡　　　　　　 ／　　 ／　｀､　　　／　　 ｀　ー ､ ＿＿ヽ　　 ヽ　 　  ヽ 、\n",
    "    　　　　　 　 　 　 ／ 　 ／　　　 /　　 /　　　　　　　　 　 　 　 ＼　 丶　- ､ ｀､\n",
    "    　　　　　　　　　/　.／　　　　／ 　 ／　　　　　　　　　　　　　　　 ＼　｀､　　＼＼\n",
    "    　　　　 　 　 .／.／　　　　　 |　　/　　　　　　　　　　　　　　　 　  ＼ 丶 　 　ヽ ヽ\n",
    "    　　　 　 ___／.／　 　 　 　 　 |　|　　　　　　　　　　　　　　　　　　　ヽ｀､ 　 　｀､｀､\n",
    "    　　　　/ |__／　　　　　　　　　 | |　　　　　　　　　　　　　　　　　　　　｀､ヽ、　　 ｔﾆゝ\n",
    "    　　 　 ￣　　 　 　 　 　 　 \"\"\"\"''\"\"'\"\" 　　　　　　　　　　　　　 　 　 　 ヽ ､ヽ　　　\n",
    "    　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　 　 　 　 　 　 ｔﾆゝ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のコマンドをターミナルに入力して，ログを見る  \n",
    "conda activate env_pytorch  \n",
    "tensorboard --logdir runs  \n",
    "終わるとき➡ctrlキーとcを同時に入力  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
